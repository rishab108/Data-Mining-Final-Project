{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from string import atoi\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"ContentBased\")\n",
    "conf = conf.setMaster(\"local[*]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc  = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test and Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = \"/Users/lakshya/Desktop/INF-553/Project/pittsburgh_review_with_text_20_res_lemma_data_train.txt\"\n",
    "test_file = \"/Users/lakshya/Desktop/INF-553/Project/pittsburgh_review_with_text_20_res_lemma_data_test.txt\"\n",
    "category_file = \"/Users/lakshya/Desktop/INF-553/Project/pitts_bus_20_attributes_categories.txt\"\n",
    "train_output = '/Users/lakshya/Desktop/INF-553/Project/Pittsburgh_CategoryBased_TFIDF_train_predictions.txt'\n",
    "test_output = '/Users/lakshya/Desktop/INF-553/Project/Pittsburgh_CategoryBased_TFIDF_test_predictions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData = sc.textFile(train_file ,use_unicode=False)\n",
    "testData = sc.textFile(test_file ,use_unicode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rdd = trainData.mapPartitions(lambda x: csv.reader(x)).map(lambda x: ((x[0], x[1]), float(x[2])))\n",
    "test_rdd = testData.mapPartitions(lambda x: csv.reader(x)).map(lambda x: ((x[0], x[1]), float(x[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average rating of users and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_rating = train_rdd.map(lambda x: (x[0][0], x[1])).groupByKey().map(lambda x: (x[0], list(x[1]))).map(lambda x: (x[0], sum(x[1])/len(x[1])))\n",
    "prod_rating = train_rdd.map(lambda x: (x[0][1], x[1])).groupByKey().map(lambda x: (x[0], list(x[1]))).map(lambda x: (x[0], sum(x[1])/len(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_temp = trainData.mapPartitions(lambda x: csv.reader(x)).map(lambda x: ((x[0], x[1]), x[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load product category data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(category_file,use_unicode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"f2FfutZhb4F-m1Ob0EdYaw\",\"asian fusion caterers fast food chinese restaurants vegetarian food delivery services event planning  services food  alcohol_full_bar ambience_casual bikeparking businessacceptscreditcards businessparking_street caters goodforkids goodformeal_dinner hastv noiselevel_average restaurantsattire_casual restaurantsdelivery restaurantsgoodforgroups restaurantspricerange2_2 restaurantstableservice restaurantstakeout wheelchairaccessible \"',\n",
       " '\"qfcdMhm1Ff28JHVpHca20g\",\"pizza restaurants  businessacceptscreditcards restaurantsattire_casual restaurantspricerange2_2 restaurantstakeout \"',\n",
       " '\"wHUru-79ExNRanJtwZEYeA\",\"\"',\n",
       " '\"rreIYrzI9U052p7nN_qogA\",\"sushi bars food thai poke japanese restaurants   ambience_casual bikeparking businessacceptscreditcards caters goodforkids goodformeal_lunch goodformeal_dinner noiselevel_average restaurantsattire_casual restaurantspricerange2_2 restaurantstakeout \"',\n",
       " '\"eva56motCJcevOwKzyQO1g\",\"cafes hotels  travel swimming pools travel services hiking playgrounds local services skating rinks beaches visitor centers restaurants tennis community service/non-profit parks active life  bikeparking businessacceptscreditcards businessparking_street goodforkids wheelchairaccessible \"',\n",
       " '\"dUeEAGxEwMv1Tafj6yr1BA\",\"food cafes coffee  tea restaurants  \"']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = data.mapPartitions(lambda x: csv.reader(x)).map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f2FfutZhb4F-m1Ob0EdYaw',\n",
       "  'asian fusion caterers fast food chinese restaurants vegetarian food delivery services event planning  services food  alcohol_full_bar ambience_casual bikeparking businessacceptscreditcards businessparking_street caters goodforkids goodformeal_dinner hastv noiselevel_average restaurantsattire_casual restaurantsdelivery restaurantsgoodforgroups restaurantspricerange2_2 restaurantstableservice restaurantstakeout wheelchairaccessible '),\n",
       " ('qfcdMhm1Ff28JHVpHca20g',\n",
       "  'pizza restaurants  businessacceptscreditcards restaurantsattire_casual restaurantspricerange2_2 restaurantstakeout '),\n",
       " ('wHUru-79ExNRanJtwZEYeA', '')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect user data from train data (User, Product, Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userReview = train_data.map(lambda x: (x[0][0], x[0][1], x[1][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userReviewCollected = train_temp.map(lambda x: (x[0][0], x[0][1], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1VVHf1BvtGC0aSCCIjQyiA', 'K5jY2W5Q3eNnwssV5UZtow', '4'),\n",
       " ('QYKexxaOJQlseGWmc6soRg', 'rzByiKaj-bLeLz-zKNBQdg', '2'),\n",
       " ('-ARdx8hOcEWlMDjzwLYZ_g', '3cbsPfoUUrysf-M8FI_0IA', '4'),\n",
       " ('2oTG2GrBpikkonRxQywI7Q', 'CFtZH4Skp9z3o4ToSywI4w', '4'),\n",
       " ('B7aR8VlLMGzaJ7NHC-jeMQ', 'RC8NJlX3X2Eo240PU5zJWA', '4')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userReviewCollected.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect product data (Product, Category Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prodReview = train_data.map(lambda x: (x[0], x[1])).groupByKey().mapValues(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prodReviewCollected = prodReview.map(lambda x: (x[0], \" \".join(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MvlQo4bev1eqp1q0HYOLHg',\n",
       "  'professional services performing arts arts  entertainment fitness  instruction dance studios active life education  bikeparking businessparking_street byappointmentonly goodforkids wheelchairaccessible '),\n",
       " ('jemRU9DvmS0WGZuZ-k3jCQ',\n",
       "  'desserts food shaved ice ice cream  frozen yogurt  bikeparking businessacceptscreditcards businessparking_lot caters restaurantspricerange2_1 restaurantstakeout '),\n",
       " ('PuMpFTKS6gY_e31UP5YVnw',\n",
       "  'restaurants american_new  bikeparking businessacceptscreditcards goodforkids hastv restaurantsattire_casual restaurantsgoodforgroups restaurantspricerange2_1 restaurantstakeout '),\n",
       " ('5S8KaaAIjqo2bJcVlMNW5w',\n",
       "  'chinese restaurants  businessacceptscreditcards restaurantsattire_casual restaurantsdelivery restaurantsgoodforgroups restaurantspricerange2_2 restaurantstableservice restaurantstakeout '),\n",
       " ('xZfPdAYeimiruXuGR4nSUA',\n",
       "  'specialty food health markets vegetarian food restaurants   ambience_casual bikeparking businessacceptscreditcards businessparking_street businessparking_lot goodforkids goodformeal_lunch goodformeal_dinner noiselevel_average outdoorseating restaurantsattire_casual restaurantsgoodforgroups restaurantspricerange2_2 restaurantstakeout wheelchairaccessible wifi_free ')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodReviewCollected.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF vector creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshya/anaconda/lib/python2.7/site-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1,1),min_df=1, norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert user and product rdd to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)\n",
    "\n",
    "userPandas = userReviewCollected.toDF().toPandas()\n",
    "prodPandas = prodReviewCollected.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create TF-IDF vectors on product category text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_prod = tf.fit_transform(prodPandas['_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3192, 549)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_prod.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add TF-IDF vectors to product dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prodPandas['Vector'] = tfidf_prod.toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MvlQo4bev1eqp1q0HYOLHg</td>\n",
       "      <td>professional services performing arts arts  en...</td>\n",
       "      <td>[0.0, 0.0, 0.241807631699, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jemRU9DvmS0WGZuZ-k3jCQ</td>\n",
       "      <td>desserts food shaved ice ice cream  frozen yog...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PuMpFTKS6gY_e31UP5YVnw</td>\n",
       "      <td>restaurants american_new  bikeparking business...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5S8KaaAIjqo2bJcVlMNW5w</td>\n",
       "      <td>chinese restaurants  businessacceptscreditcard...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xZfPdAYeimiruXuGR4nSUA</td>\n",
       "      <td>specialty food health markets vegetarian food ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _1                                                 _2  \\\n",
       "0  MvlQo4bev1eqp1q0HYOLHg  professional services performing arts arts  en...   \n",
       "1  jemRU9DvmS0WGZuZ-k3jCQ  desserts food shaved ice ice cream  frozen yog...   \n",
       "2  PuMpFTKS6gY_e31UP5YVnw  restaurants american_new  bikeparking business...   \n",
       "3  5S8KaaAIjqo2bJcVlMNW5w  chinese restaurants  businessacceptscreditcard...   \n",
       "4  xZfPdAYeimiruXuGR4nSUA  specialty food health markets vegetarian food ...   \n",
       "\n",
       "                                              Vector  \n",
       "0  [0.0, 0.0, 0.241807631699, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodPandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product category text not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del prodPandas['_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Linear Combination of product vectors for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userPandas['Vector'] = [[] for _ in range(len(userPandas))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userPandas['_3'] = userPandas['_3'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in userPandas.iterrows():\n",
    "    vector = np.array(prodPandas.loc[prodPandas['_1'] == row['_2'], 'Vector'].values[0])\n",
    "    rating = row['_3']\n",
    "    userPandas.at[index,'Vector'] = rating*vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "      <th>_3</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1VVHf1BvtGC0aSCCIjQyiA</td>\n",
       "      <td>K5jY2W5Q3eNnwssV5UZtow</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QYKexxaOJQlseGWmc6soRg</td>\n",
       "      <td>rzByiKaj-bLeLz-zKNBQdg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-ARdx8hOcEWlMDjzwLYZ_g</td>\n",
       "      <td>3cbsPfoUUrysf-M8FI_0IA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2oTG2GrBpikkonRxQywI7Q</td>\n",
       "      <td>CFtZH4Skp9z3o4ToSywI4w</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B7aR8VlLMGzaJ7NHC-jeMQ</td>\n",
       "      <td>RC8NJlX3X2Eo240PU5zJWA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _1                      _2   _3  \\\n",
       "0  1VVHf1BvtGC0aSCCIjQyiA  K5jY2W5Q3eNnwssV5UZtow  4.0   \n",
       "1  QYKexxaOJQlseGWmc6soRg  rzByiKaj-bLeLz-zKNBQdg  2.0   \n",
       "2  -ARdx8hOcEWlMDjzwLYZ_g  3cbsPfoUUrysf-M8FI_0IA  4.0   \n",
       "3  2oTG2GrBpikkonRxQywI7Q  CFtZH4Skp9z3o4ToSywI4w  4.0   \n",
       "4  B7aR8VlLMGzaJ7NHC-jeMQ  RC8NJlX3X2Eo240PU5zJWA  4.0   \n",
       "\n",
       "                                              Vector  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userPandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product and rating column not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del userPandas['_2']\n",
    "del userPandas['_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear combination of feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userPandas = userPandas.groupby(['_1']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the user feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in userPandas.iterrows():\n",
    "    vector = np.array(row['Vector']).reshape(1, -1)\n",
    "    transformer = Normalizer().fit(vector)\n",
    "    userPandas.at[index,'Vector'] = transformer.transform(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-0-hVEpwWEcJLJoGq3rE3g</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2OB54nQ6FsGLUM-R1KXnA</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-ARdx8hOcEWlMDjzwLYZ_g</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0028831...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Pk25bOBsvemFaWKDBVBzA</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Q2wBtscwW6JOqlBndji4A</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Vector\n",
       "_1                                                                       \n",
       "-0-hVEpwWEcJLJoGq3rE3g  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "-2OB54nQ6FsGLUM-R1KXnA  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "-ARdx8hOcEWlMDjzwLYZ_g  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0028831...\n",
       "-Pk25bOBsvemFaWKDBVBzA  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "-Q2wBtscwW6JOqlBndji4A  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userPandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create user numpy matrix from feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_matrix = np.zeros((len(userPandas), tfidf_prod.shape[1]))\n",
    "idx = 0\n",
    "for index, row in userPandas.iterrows():\n",
    "    vector = np.array(row['Vector'])[0]\n",
    "    user_matrix[idx] = vector\n",
    "    idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.02265067,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.00660732,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.01025369, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.0176749 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.04647705,  0.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create product numpy matrix from feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod_matrix = np.zeros((len(prodPandas), tfidf_prod.shape[1]))\n",
    "idx = 0\n",
    "for index, row in prodPandas.iterrows():\n",
    "    vector = np.array(row['Vector'])\n",
    "    prod_matrix[idx] = vector\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.24180763, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cosine similarity by taking dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity_matrix = np.dot(user_matrix, prod_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987, 3192)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten similarity matrix to related with user and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod = prodPandas['_1'].values\n",
    "user = userPandas.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zf = similarity_matrix.flatten()\n",
    "xr = np.repeat(user, prod.size)\n",
    "yt = np.tile(prod, user.size)\n",
    "d = np.stack((xr, yt, zf), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3150504, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert similarity matrix to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity_rdd = sc.parallelize(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([u'-0-hVEpwWEcJLJoGq3rE3g', u'MvlQo4bev1eqp1q0HYOLHg',\n",
       "        0.08688367393230353], dtype=object),\n",
       " array([u'-0-hVEpwWEcJLJoGq3rE3g', u'jemRU9DvmS0WGZuZ-k3jCQ',\n",
       "        0.19204449974292587], dtype=object),\n",
       " array([u'-0-hVEpwWEcJLJoGq3rE3g', u'PuMpFTKS6gY_e31UP5YVnw',\n",
       "        0.4513868048288503], dtype=object),\n",
       " array([u'-0-hVEpwWEcJLJoGq3rE3g', u'5S8KaaAIjqo2bJcVlMNW5w',\n",
       "        0.3120304916702723], dtype=object),\n",
       " array([u'-0-hVEpwWEcJLJoGq3rE3g', u'xZfPdAYeimiruXuGR4nSUA',\n",
       "        0.4458662409733761], dtype=object)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Train and Test Data for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1VVHf1BvtGC0aSCCIjQyiA,K5jY2W5Q3eNnwssV5UZtow,4,2016-11-16,2,2,2,past sunday one several time ive spirit its always eccentric fun time first music performance second hang recent visit sundays bingo bango spirit know pizza good drink also awesome last time get chard margarita time get tomatillo margarita hot ciders its always pleasant surprise see whats menu food drink drink little pricey drawback one coolest things spirit atmosphere its always super strange positive way really never know expect bingo bango definitely family appropriate its fun activity friends maybe even date doesnt mind something ordinary',\n",
       " 'QYKexxaOJQlseGWmc6soRg,rzByiKaj-bLeLz-zKNBQdg,2,2015-04-13,0,0,0,old cramp build lot enough employees staff keep demand cause long wait time',\n",
       " '-ARdx8hOcEWlMDjzwLYZ_g,3cbsPfoUUrysf-M8FI_0IA,4,2014-03-24,6,4,3,live long world without donut menu dont know group nine din three varieties donuts include lemon lavender chocolate espresso zeppolli amaze pepper donut concoction ever make donut order come five donut hole theyre big hole one two enough cant believe say thats even little true youll want entire order save room best yet come choose omelette day entr\\xc3\\xa9e couldnt tell goat cheese creamy goats cheese salad nice addition potatoes delightful touch underdone seat downstairs pretty frigid awesome space nonetheless warm joint bite its five star way cant wait visit e2 dinner serve donuts right',\n",
       " '2oTG2GrBpikkonRxQywI7Q,CFtZH4Skp9z3o4ToSywI4w,4,2015-04-02,0,0,0,month try place try years ago im actually quite surprise place get earlier review sample veggie burger goodness place event attend couple years ago become close top list try finally go friend couple weeks ago try veggie burger call hippie something another burger feel like tony tiger fry good beer good fry good venue wait staff pretty great around good yummy experience',\n",
       " 'B7aR8VlLMGzaJ7NHC-jeMQ,RC8NJlX3X2Eo240PU5zJWA,4,2013-02-16,1,0,0,food good find service tad slow italian place area would go first italian good yes excellent meatballs']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create key on (user, product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rdd = trainData.mapPartitions(lambda x: csv.reader(x)).map(lambda x: ((x[0], x[1]), float(x[2])))\n",
    "test_rdd = testData.mapPartitions(lambda x: csv.reader(x)).map(lambda x: ((x[0], x[1]), float(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity_rdd = similarity_rdd.map(lambda x: ((x[0], x[1]), float(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('JiPMk9WmbJu-VfTRAKpZpw', 'PdDpIGwBZoTYzOVasT-WuA'), 4.0),\n",
       " (('2wKnvn68eWybc7ID-7UQmQ', 'khRo2a5OaIjumox-tkg3GA'), 4.0),\n",
       " (('LsWpfxWjLQcazDqnZ_A62g', 'D_pwairtGGR0V_w2xx5XeA'), 2.0),\n",
       " (('0N9bSCmoJMoGmR0EldzjQg', '3iaOYhNoc6XL935MqnxJSQ'), 5.0),\n",
       " (('-hietrA8M58asfpyJkCyiA', 'O1ird5yRyuDFnOmYu90OoA'), 4.0)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join similarity matrix with train and test RDD to take only similarity values for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = similarity_rdd.join(train_rdd)\n",
    "test = similarity_rdd.join(test_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'hHqH_E9FCI_B6WubV0jPYA', u'ZNdV9ytExuxPTXSN8i2xhw'),\n",
       "  (0.4430106361717298, 3.0)),\n",
       " ((u'V0pP_PQnWdtyKpF-pifiaw', u'Fpm3WvqtrAg2ueh_4pz7iA'),\n",
       "  (0.4365563378481936, 4.0)),\n",
       " ((u'IKnLl7SbuP0u6HS34jwHhw', u'guQww9yGHP7rRTea6zTnDg'),\n",
       "  (0.4510025876959838, 3.0)),\n",
       " ((u'4r33dXcE1oYZxjONrhxTiA', u'9gNko6cFCMZbvy1zhJ7-Xg'),\n",
       "  (0.5069695961244721, 5.0)),\n",
       " ((u'Rem81Xoev05aqeA-mFbM4A', u'1LUaZFVMEjodl1tbAGF3sQ'),\n",
       "  (0.5437834621620943, 4.0))]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert RDD to List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings = train.collect()\n",
    "test_ratings = test.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Regressor on similarity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to numpy array for regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for ratings in train_ratings:\n",
    "    X_train.append(ratings[1][0])\n",
    "    y_train.append(ratings[1][1])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_train = X_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for ratings in test_ratings:\n",
    "    X_test.append(ratings[1][0])\n",
    "    y_test.append(ratings[1][1])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10002, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train regressor on training data and make prediction on Test data<br>\n",
    "Computed Mean Squared Error on predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "1.0317996903\n",
      "Result:\n",
      "1.03901005046\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestRegressor(max_depth=1, n_estimators=20)\n",
    "\n",
    "rs = GradientBoostingRegressor(loss='ls', learning_rate=0.005, n_estimators=20)\n",
    "\n",
    "reg= LinearRegression()\n",
    "\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "expected = y_test\n",
    "predicted = rs.predict(X_test)\n",
    "\n",
    "train_expected = y_train\n",
    "train_predicted = rs.predict(X_train)\n",
    "\n",
    "print(\"Training:\\n%s\" % np.sqrt(mean_squared_error(train_expected, train_predicted)))\n",
    "print(\"Result:\\n%s\" % np.sqrt(mean_squared_error(expected, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computed Ratings on missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_test = test_rdd.subtractByKey(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_ratings_user = missing_test.map(lambda x: ((x[0][0]), (x[0][1], x[1]))).join(avg_rating).map(lambda x: ((x[0], x[1][0][0]), (x[1][1], x[1][0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ratings_user.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test data using the trained regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = test.map(lambda x: ((x[0]), (rs.predict(np.array(x[1][0]).reshape(1,-1))[0], x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predictions = predictions.union(missing_ratings_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse = final_predictions.map(lambda x: (x[1][0]-x[1][1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0299346475243478"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mse.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predictions = final_predictions.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(test_output, 'w') as f:\n",
    "    for item in final_predictions:\n",
    "        f.write(str(item[0][0])+\",\"+str(item[0][1])+\",\"+str(item[1][0])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predict = train.map(lambda x: ((x[0]), (rs.predict(np.array(x[1][0]).reshape(1,-1))[0], x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'cCke3VtFLtqgzkgYSrSE2g', u'BMR_AsSBzTQHqW-SQabI4w'),\n",
       "  (3.8326497101895205, 4.0)),\n",
       " ((u'YE54kKTuqJJPNYWIKIpOEQ', u'RvwZqjdkZ_pER0moPXLZAQ'),\n",
       "  (3.8326497101895205, 3.0)),\n",
       " ((u'4wp4XI9AxKNqJima-xahlg', u'ziJsGjXvidzZWC1I0-SOSg'),\n",
       "  (3.828575120737566, 3.0)),\n",
       " ((u'U92V-gp13uMZL-sl_naTHA', u'zi6cB_bkswWPLD2k3IVtyg'),\n",
       "  (3.828575120737566, 4.0)),\n",
       " ((u'rZQCd47n7OwPd71igVX6Og', u'IfHkboQZGPZkKpqHZCW4ag'),\n",
       "  (3.8326497101895205, 1.0))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions = train_predict.map(lambda x: (x[1][0]-x[1][1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.03320310263514"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(train_predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predict = train_predict.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(train_output, 'w') as f:\n",
    "    for item in train_predict:\n",
    "        f.write(str(item[0][0])+\",\"+str(item[0][1])+\",\"+str(item[1][0])+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
